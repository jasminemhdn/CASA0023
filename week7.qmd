# Sub-pixel-based vs Object-based Classification

## Summary: More Type of Classification and Accuracy Assessment

Beside categorised based on the use of training data and a priori knowledge, remote sensing classification can be divided into sub-pixel-based and object-based classification.

### Sub-pixel-based Classification

Sub-pixel classification recognizes that each pixel can contain multiple land-cover types. This method estimates the fractional composition of each pixel based on spectral properties. Itâ€™s especially useful when working with coarse-resolution imagery. Sub-pixel classification highly accurate for representing fractional information within mixed pixels. Particularly suitable for coarse resolution imagery where pixels represent multiple land covers. The accuracy significantly depends on correct endmember identification; incorrect or missing endmembers can cause misclassification and decrease overall accuracy.

Examples of sub-pixel classification methods include:

-   Linear Spectral Unmixing (LSU): Uses pure endmembers to estimate fractional abundances within each pixel.

-   Multiple Endmember Spectral Mixture Analysis (MESMA): Allows different combinations of endmembers to model pixel composition dynamically.

### Object-based Classification

Object-based classification groups pixels into meaningful objects or segments based on spatial, spectral, and textural properties before classification. Unlike traditional methods, object-based approaches classify objects rather than individual pixels, making use of spatial context. OBIA typically achieves higher classification accuracy compared to traditional pixel-based methods because it incorporates contextual information (shape, texture, spatial arrangement), reducing noise and improving class boundaries. However, accuracy strongly relies on segmentation quality; poor segmentation can lead to misclassification and reduce overall accuracy.

Examples of object-based classification workflows typically involve two main stages:

-   Segmentation: Pixels grouped into homogeneous objects based on spatial, spectral, and textural similarity.

-   Classification: Objects classified into land cover categories using algorithms such as Random Forest, Support Vector Machine (SVM), or Decision Trees.

### Classification Accuracy Assessment

Accuracy assessment is a process that should never be skipped when doing image classification. This process generally involves comparison between classified results and reference (ground-truth) data. The three most common types of accuracy measures are:

-   Producer's Accuracy: this measures how well a class in the reference data is correctly classified. It indicates omission error, reflecting cases where a pixel of a certain class was mistakenly omitted (missed).

-   User's Accuracy: this measures the reliability from the user's perspective, indicating commission errors. Commission errors happen when pixels are incorrectly classified into a category they do not belong to.

-   Overall Accuracy: measures the overall performance by comparing the total number of correctly classified pixels with the total number of reference pixels.

## Application: Building Footprints Extraction

Both papers by Chen et al. (2020) and Li et al. (2019) focus on building extraction using high-resolution satellite imagery but apply different approaches. Chen et al. (2020) uses object-based classification by combining SLIC segmentation and a multi-modal CNN that processes both PAN and MS images from GF-2 in Wuhan, China. Meanwhile, Li et al. (2019) applies a pixel-based semantic segmentation using U-Net on pan-sharpened WorldView-3 imagery across four global cities. I find Chen et al.'s method interesting because it extracts building shapes more accurately by combining spatial and spectral features through object-based segments. The use of radiometric and atmospheric correction (FLAASH) before feature extraction is a strength, as it helps reduce spectral inconsistencies. However, the method relies heavily on segmentation quality, and its performance may drop if the objects are poorly defined. Li et al. (2019), on the other hand, takes a more scalable approach. Testing their method across diverse cities makes it more applicable globally. I like that they combine multi-source GIS data for validation and apply data augmentation and post-processing to improve results. However, there is no clear mention of atmospheric or radiometric correction, which could affect consistency, especially when using data from different cities. Their result in Khartoum was also less accurate, showing challenges in detecting buildings in low-contrast or shaded areas.

## Reflection: The Complexities of Sub-pixel-based and Object-based Classification

Truthfully, I think this topic is the most difficult one compared to other topics in this module. So far, building extraction is the only example that comes to mind when learning about object-based and sub-pixel-based classification. I find it quite tricky to distinguish between both, especially because these days, a lot of deep learning methods blur the line between pixel and object level analysis. What I realize is that object-based classification relies more on image segmentation, so the result heavily depends on how well the objects are grouped, while pixel-based methods classify every pixel without considering the spatial context, which makes it faster but also more prone to misclassification especially around boundaries. Other than for building extraction, I think methods can also be applied in various urban analyses such as detecting rooftop solar PV, greenhouses, green rooftops, or tree detection such as palm tree.
