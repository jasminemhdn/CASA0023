[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning Diary - CASA0023: Remotely Sensing Cities and Environment",
    "section": "",
    "text": "Personal Introduction\nMy name is Jasmine Mahdani and I am from Indonesia. I graduated from ITB (Bandung Institute of Technology) in 2022, majoring in Geodesy and Geomatic Engineering. During my undergraduate years, I had been actively engaged in research particularly for urban related issues using GIS and remote sensing. My research topic focus on water and sanitation access, slum identification, and disaster risk assessment. My enthusiasm to urban issues and GIS continues after I graduate that leads me to choose urban spatial researcher as my career path. However, doing spatial analysis for urban issues is quite tricky because the coverage area is relatively small and finding open source detailed data set in Indonesia is extremely hard. Moreover, I also have limited knowledge on how urban system works. Therefore, I decided to pursue master degree in Urban Spatial Science at UCL (University College London) to deepen my knowledge in urban analytics and to support my career path as a researcher. In Urban Spatial Science, I take the Urban Modelling and Simulation pathway and Remotely Sensing Cities and Environment modules in hope I can answer the challenge of using open sourced medium spatial resolution remote sensing data for urban research that mostly have small coverage area.",
    "crumbs": [
      "Personal Introduction"
    ]
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "1  Introduction to Remote Sensing",
    "section": "",
    "text": "1.1 Summary: Remote Sensing Definition and How it Works\nRemote sensing is the practice of obtaining information about the Earth’s surface, using images acquired from airborne or spaceborne vehicles by measuring reflected, emitted, or returned electromagnetic radiation (Ruth DeFries, 2013). The objective of this technology is to provide observation of physical parameter in a mapping frame at a given time period (Toth & Jozkow, 2016).\nRemote sensing captures the electromagnetic (EM) radiation that is reflected from earth’s surface. EM wave is an energy that travels through the light. All matters with absolute temperature above zero reflect and emit EM waves of various length (J. M. Read and M. Torrado, 2009). A material that fully capable of absorbing and re-emitting all EM energy that it receives is called a blackbody, but it is rare and most natural objects only absorb some of the energy (Tempfli K. et al., 2009). The difference in how objects absorb and reflect energy is what’s make every earth’s feature has its own signature characteristic which is recorded as digital number (DN) in each pixel of images using the sensors.\nIn remote sensing, there are two type of sensors, passive and active that are used for different applications. Most sensors use passive systems which can only capture the reflection of sun’s energy and work during daylight. Therefore, this sensors’ orbit sometimes are set to follow’s the sun (sun-synchronous). The electromagnetic spectrum recorded by the sensors range from ultraviolet (UV), visible (red, green, blue), infrared (IR), and microwave. Meanwhile, active remote sensing can radiate its own energy and measure the amount of radiation returned to the sensor. Active sensors can penetrate through clouds and won’t be affected by daylight or weather conditions. Example of active sensors included SAR and LIDAR.\nAlthough remote sensing is great for collecting data in inaccessible area and cheaper for mapping large areas, there are 4 type of resolution that needs to be considered when using it: spatial, spectral, temporal, and radiometric. Spatial resolution refers to the size of area measured which is represented by each pixel. Spectral refer to the range of wavelength the sensor is sensitive to. Radiometric refer to the difference in radiation intensity. Temporal characteristics refer to the time of image acquisition. These resolutions need to be considered based on the purpose of the mapping.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "week1.html#application-example-of-landsat-and-sentinel-for-urban-heat-island-uhi",
    "href": "week1.html#application-example-of-landsat-and-sentinel-for-urban-heat-island-uhi",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.2 Application: Example of Landsat and Sentinel for Urban Heat Island (UHI)",
    "text": "1.2 Application: Example of Landsat and Sentinel for Urban Heat Island (UHI)\nWith the growing technology, remote sensing becomes more advanced and freely available. The development of single sensor to multiple sensors allows spatial researcher to do environmental and social research using it. The example of application includes biodiversity monitoring, crop classification, hazards modelling, Urban Heat Island monitoring, LULC classification, and carbon sequestration modelling (Roy et al., 2017). Sometimes people compare and combine multiple sensors from different platform to get accurate and comprehensive results because different sensors capturing the same area might get different reflectance values. Examples of known satellites for research are Terra, MODIS, SPOT, Landsat, and Sentinel (Toth & Jozkow, 2016).\nThe paper by Rech et al., (2024) gives example of using Landsat 8 TIRS band for mapping Surface Urban Heat Islands (SUHI) and assess the SUHI relation to albedo, elevation, land surface emissivity, and vegetation cover across Local Climate Zones (LCZ) in Florianopolis, Brazil. The paper assessing the variability of SUHI between day and night, different LCZ and different surface using multiple statistical approaches. Although the paper mentioned using Practical Single-Channel (PSC) algorithm to derive LST, the result does not explain the accuracy of the methods or the LST before used for analysis and instead only focuses on the variability with the parameters. Since the study area is a humid region, the use of PSC method give concern on its reliability. However, I think the author has tried it best to find images with low cloud cover and no rain. Unfortunately, there’s only one pair that meets these criteria, so it’s not feasible to conduct the study for different seasons. Moreover, since the TIRS band already resampled to 30 meters, I think it would be good if they zoom in to some specific areas to show variability.\nMeanwhile, the paper by García and Díaz (2021) used Sentinel-3 to Meanwhile, the paper by García and Díaz (2021) used Sentinel-3 to derive LST and applied Split-Window Correction for assessing Urban Heat Island and factors contributing to it in Granada, Spain. Different from previous one, this study compares the value derived from Sentinel-3 with in-situ analysis. The result shows Sentinel-3 temperature is a little bit higher. The study also conduct analysis for different seasons because Sentinel-3 temporal resolution is daily giving more available data to used. However, the Sentinel-3 1 km resolution might not be as detailed as Landsat 8, even though the author had tried to resample it to 100 meters.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "week1.html#reflection-challenges-in-remote-sensing-and-potential-future-study",
    "href": "week1.html#reflection-challenges-in-remote-sensing-and-potential-future-study",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.3 Reflection: Challenges in Remote Sensing and Potential Future Study",
    "text": "1.3 Reflection: Challenges in Remote Sensing and Potential Future Study\nSince I have been learning about remote sensing on my undergraduate degree before, the material about sensors and electromagnetic reflectance are already familiar for me. I also have used some remote sensing data for my research and since the first time I know about it, I always think remote sensing mapping is a cheaper method for large area compared to other mapping techniques. However, when I did the practical using SNAP for Sentinel-2 and Landsat-8 data, I started to think even though the medium spatial resolution remote sensing images are freely available, we still need high specification computer to process it because one tiles comprised of several bands are huge and my laptop somewhat need to work hard to do the resampling and other practical. It also made me realise that it’s not quite efficient to do preprocessing of these images from scratch when you only want to do research on very small area especially when the boundary does not overlap perfectly with the image. I think using Google Earth Engine (GEE) which would be explained in the later weeks is better because they provide some already pre-processed images and its based-on cloud, so you don’t need high specification computer. Beside this issue, I also think that this ‘cheaper method’ only applies to regional-based analysis that can use medium spatial resolution like Landsat and Sentinel-2. Meanwhile, if you want to do a detailed analysis on city like how the UHI effect on different surface and LCZ, especially for building level, it will need high spatial resolution which are mostly still commercial. The resampling methods may give us immediate solution for this although we still need to consider the impact of each method that may affect the analysis. However, despite all the challenges in remote sensing approaches, I still think it’s the most robust method in the present that can give comprehensive result when its used and combined with other dataset appropriately. To this day, I still have a goal to do UHI analysis on building level using open-source remote sensing data. I believe remote sensing technology would develop even further that gives more better resolution from the existing ones.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Xaringan Presentation and Quarto Book",
    "section": "",
    "text": "2.1 Reflection: Make Slides using Xaringan\nThis is my first time learning how to make presentation by writing it in Xaringan instead of directly place the words and figures in slides like in Microsoft Powerpoint. The Xaringan might quite simple, but I actually prefer a simple presentation. It is good that I don’t have to think about symmetrical placement of the word and figures because they are already placed automatically and I just have to specify the location using middle, center, or .pull-left and .pull-right. Also, the use of github making it easier to collaborate with colleagues and can be accessible for everyone at anytime and anywhere. My favorite part is the tab part in single slides. Usually for information like resolutions for different instrument (slides 4), I would display it as a table, but from now on I think I will use tab a lot since it gives more space for explanation but because they are placed in one slides it makes more efficient.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Xaringan Presentation and Quarto Book</span>"
    ]
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "3  Remote Sensing Image Corrections and Enhancement",
    "section": "",
    "text": "3.1 Summary: Type of Corrections and Enhancement\nRemote sensing images contain bias and error from earth’s rotation, terrain and atmospheric condition that may affect the surface reflectance. Below is the summary of correction applied to remote sensing for the pre-processing process.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Remote Sensing Image Corrections and Enhancement</span>"
    ]
  },
  {
    "objectID": "week3.html#summary-type-of-corrections-and-enhancement",
    "href": "week3.html#summary-type-of-corrections-and-enhancement",
    "title": "3  Remote Sensing Image Corrections and Enhancement",
    "section": "",
    "text": "Geometric Correction\nGeometric correction is used to remove or reduce the effect of Earth rotation and terrain during the scanning of an image. The table below shows the example of geometric correction approaches.\n\nGeometric Correction Methods\n\n\n\n\n\n\nMethods\nDescription\n\n\n\n\nGeoreferencing\nThe process of link an image to a map projection by using geometric transformation. Points in identical places that captured in two different images or systems is the key points in georeferencing.\n\n\nGeocoding\nThe process use to transform row/column structure of the image (resampling). Geocoding is required to combine different images.\n\n\n\n\n\nRadiometric Correction\nThe radiometric correction deals with the radiance values of reflected polychromatic solar radiation and the emitted thermal radiance from Earth’s surface. The atmosphere cause the radiance value to be altered when recorded by the satellite. In general the radiometric correction is divided into cosmetic correction and atmospheric correction.\n\nRadiometric Correction Methods\n\n\n\n\n\n\nMethods\nDescription\n\n\n\n\nCosmetic\nCosmetic correction use filters, image stretching, and image enhancement to correct visible errors and noise in the image data without involving atmospheric model.\n\n\nAtmospheric\nAtmospheric correction is applied to remove the atmospheric effect by using models. There are two types of this correction: relative (does not require atmospheric component) and absolute (require atmospheric component).\n\n\n\n\n\nEnchancement\nImage enhancement is the procedure of improving the quality and information content of original data (Haldar, 2018). The table below explain each of the methods.\n\nImage Enhancement Methods\n\n\n\n\n\n\nMethods\nDescription\n\n\n\n\nContrast Enhancemenet\nContrast enhancement or stretching is performed by linear transformation expanding the original range of gray level.\n\n\nSpatial Filtering\nSpatial filtering improves the naturally occurring linear features like fault, shear zones, and lineaments.\n\n\nDensity Slicing\nDensity slicing converts the continuous gray tone range into a series of density intervals marked by a separate color or symbol to represent different features.\n\n\nFCC\nFCC is commonly used in remote sensing compared to true colors because of the absence of a pure blue color band because further scattering is dominant in the blue wavelength.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Remote Sensing Image Corrections and Enhancement</span>"
    ]
  },
  {
    "objectID": "week3.html#application",
    "href": "week3.html#application",
    "title": "3  Remote Sensing Image Corrections and Enhancement",
    "section": "3.2 Application:",
    "text": "3.2 Application:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Remote Sensing Image Corrections and Enhancement</span>"
    ]
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "3  Remote Sensing Image Corrections and Enhancement",
    "section": "3.3 Reflection:",
    "text": "3.3 Reflection:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Remote Sensing Image Corrections and Enhancement</span>"
    ]
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "5  Introduction to Google Earth Engine (GEE)",
    "section": "",
    "text": "5.1 Summary: GEE Function and Interface\nGoogle Earth Engine (GEE) is a cloud-based remote sensing data processing that allows us to access huge variety of open-source remote sensing product such as Landsat, Sentinel, and MODIS or raster product made by other people such as Impervious Surface. To use GEE, we must create an account first using Google account. GEE is connected directly to Google Drive, so we can save the unprocessed or already processed data into Google Drive and download it in case we want to use it for processing or lay outing the maps in GIS application such as QGIS. However, if the data too big, it would require large Google Drive space. Another alternative to store the processed data or present the maps online is by using Asset and Web Apps. This allows us to access the data we have already processed before for another analysis.\nJavaScript is the main programming language used in GEE. But, we could also use Python when GEE is connected to Google Colab, Jupyter Notebook or QGIS. Even though it seems that JavaScript is harder to understand, GEE provides explanation of every syntax in Docs Panel. The picture below shows the GEE interface.\nAnd this is the explanation of each part of the interface:\nThe picture below shows the example of MODIS Terra data catalog in GEE. In this catalog, there are information containing data availability, description of the data, raster bands and its spatial resolution, terms of use, citation, and dois. If we want to use this data, we can click IMPORT button in bottom right.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Google Earth Engine (GEE)</span>"
    ]
  },
  {
    "objectID": "week5.html#summary",
    "href": "week5.html#summary",
    "title": "5  Introduction to Google Earth Engine (GEE)",
    "section": "",
    "text": "Script Panel: this panel store the scripts that has been saved and it allows us to create and load scripts.\nDocs Panel: store the documentation and function description of GEE commands.\nAssets Panel: a storage space to upload raster or vector data in GEE.\nConsole Panel: displays outputs, print statements, and errors when running scripts.\nMap Panel: display geospatial datasets and analysis results.\nTask Manager: manages long-running tasks like exporting images, tables, or maps.\nInspector Panel: allows us to click on the map and inspect pixel values.\nGet Link: generate a shareable URL for the script and map view.\nSave: save the current script.\nRun: executes the script and applies it to the Map Panel.\nReset: clears all variables, print outputs, and layers.\nApps: provides access to custom web apps created in GEE.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Google Earth Engine (GEE)</span>"
    ]
  },
  {
    "objectID": "week5.html#application",
    "href": "week5.html#application",
    "title": "5  Introduction to Google Earth Engine (GEE)",
    "section": "5.2 Application:",
    "text": "5.2 Application:",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Google Earth Engine (GEE)</span>"
    ]
  },
  {
    "objectID": "week5.html#reflection",
    "href": "week5.html#reflection",
    "title": "5  Introduction to Google Earth Engine (GEE)",
    "section": "5.3 Reflection:",
    "text": "5.3 Reflection:",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Google Earth Engine (GEE)</span>"
    ]
  },
  {
    "objectID": "week5.html#summary-gee-function-and-interface",
    "href": "week5.html#summary-gee-function-and-interface",
    "title": "5  Introduction to Google Earth Engine (GEE)",
    "section": "",
    "text": "Script Panel: this panel store the scripts that has been saved and it allows us to create and load scripts.\nDocs Panel: store the documentation and function description of GEE commands.\nAssets Panel: a storage space to upload raster or vector data in GEE.\nConsole Panel: displays outputs, print statements, and errors when running scripts.\nMap Panel: display geospatial datasets and analysis results.\nTask Manager: manages long-running tasks like exporting images, tables, or maps.\nInspector Panel: allows us to click on the map and inspect pixel values.\nGet Link: generate a shareable URL for the script and map view.\nSave: save the current script.\nRun: executes the script and applies it to the Map Panel.\nReset: clears all variables, print outputs, and layers.\nApps: provides access to custom web apps created in GEE.\nSearch Bar: find datasets, function, or scripts.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Google Earth Engine (GEE)</span>"
    ]
  },
  {
    "objectID": "week5.html#application-identification-of-plastic-waste-accumulation-in-gee",
    "href": "week5.html#application-identification-of-plastic-waste-accumulation-in-gee",
    "title": "5  Introduction to Google Earth Engine (GEE)",
    "section": "5.2 Application: Identification of Plastic Waste Accumulation in GEE",
    "text": "5.2 Application: Identification of Plastic Waste Accumulation in GEE",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Google Earth Engine (GEE)</span>"
    ]
  },
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "6  Supervised vs Unsupervised Classification",
    "section": "",
    "text": "6.1 Summary:",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Supervised vs Unsupervised Classification</span>"
    ]
  },
  {
    "objectID": "week6.html#application",
    "href": "week6.html#application",
    "title": "6  Supervised vs Unsupervised Classification",
    "section": "6.2 Application:",
    "text": "6.2 Application:",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Supervised vs Unsupervised Classification</span>"
    ]
  },
  {
    "objectID": "week6.html#reflection",
    "href": "week6.html#reflection",
    "title": "6  Supervised vs Unsupervised Classification",
    "section": "6.3 Reflection:",
    "text": "6.3 Reflection:",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Supervised vs Unsupervised Classification</span>"
    ]
  },
  {
    "objectID": "week7.html",
    "href": "week7.html",
    "title": "7  Pixel-based vs Object-based Classification",
    "section": "",
    "text": "7.1 Summary:",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Pixel-based vs Object-based Classification</span>"
    ]
  },
  {
    "objectID": "week7.html#application",
    "href": "week7.html#application",
    "title": "7  Pixel-based vs Object-based Classification",
    "section": "7.2 Application:",
    "text": "7.2 Application:",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Pixel-based vs Object-based Classification</span>"
    ]
  },
  {
    "objectID": "week7.html#reflection",
    "href": "week7.html#reflection",
    "title": "7  Pixel-based vs Object-based Classification",
    "section": "7.3 Reflection:",
    "text": "7.3 Reflection:",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Pixel-based vs Object-based Classification</span>"
    ]
  },
  {
    "objectID": "week8.html",
    "href": "week8.html",
    "title": "8  Introduction to Synthetic Aperture Radar (SAR)",
    "section": "",
    "text": "8.1 Summary:",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Introduction to Synthetic Aperture Radar (SAR)</span>"
    ]
  },
  {
    "objectID": "week8.html#application",
    "href": "week8.html#application",
    "title": "8  Introduction to Synthetic Aperture Radar (SAR)",
    "section": "8.2 Application:",
    "text": "8.2 Application:",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Introduction to Synthetic Aperture Radar (SAR)</span>"
    ]
  },
  {
    "objectID": "week8.html#reflection",
    "href": "week8.html#reflection",
    "title": "8  Introduction to Synthetic Aperture Radar (SAR)",
    "section": "8.3 Reflection:",
    "text": "8.3 Reflection:",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Introduction to Synthetic Aperture Radar (SAR)</span>"
    ]
  }
]